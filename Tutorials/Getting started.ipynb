{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pypads/PadrePads Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping files\n",
    "#### Default event-based loggers PyPads\n",
    "Before jumping into how to define hooks for pypads events and map them to pypads' loggers, let's have a look into the list of default loggers.\n",
    "\n",
    "| Logger  | Event | Hook | Description\n",
    "| :-------------: |:----------:|: -----------:| ----------------|\n",
    "| LogInit  | init | 'pypads_init'| Debugging purposes |\n",
    "| Log  | log | 'pypads_log'| Debugging purposes |\n",
    "| Parameters  |  parameters | 'pypads_fit'| tracks parameters of the tracked function call |\n",
    "| Cpu,Ram,Disk  |  hardware | 'pypads_fit'| track usage information, properties and other info on CPU, Memory and Disk. |\n",
    "| Input  |  input | 'pypads_fit' |tracks the input parameters of the current tracked function call. | \n",
    "| Output  | output | 'pypads_predict', 'pypads_fit' |Logs the output of the current tracked function call.| \n",
    "| Metric  | metric | 'pypads_metric' |tracks the output of the tracked metric function. | \n",
    "| PipelineTracker  | pipeline | 'pypads_fit','pypads_predict', 'pypads_transform', 'pypads_metrics'|tracks the workflow of execution of the different pipeline elements of the experiment.| \n",
    "\n",
    "**Note**: The loggers that we will focus on are:\n",
    "- Parameters: event->parameters, hook->pypads_fit\n",
    "- Input: event->input, hook->pypads_fit\n",
    "- Output: event->output, hook->pypads_fit, pypads_predict\n",
    "- Metric: event->metric, hook->pypads_metric\n",
    "\n",
    "#### Default even-based logger for PadrePads\n",
    "\n",
    "| Logger  | Event | Hook | Description\n",
    "| :-------------: |:----------:|: -----------:| ----------------|\n",
    "| Dataset  | dataset | 'pypads_dataset'| Tracking and logging your dataset object and metadata |\n",
    "| Split  | splits | 'pypads_split'| Logging the splits of your dataset, train and test indices |\n",
    "| ParameterSearch  |  parameter_search | 'pypads_param_search'| Logging a hyperparameter grid search combinations in case there was one to be tracked. |\n",
    "| Decisions  |  predictions | 'pypads_predict'| tracks individual decisions of your estimators (Predicted_value/Truth_value/Decision_score) whenever possible. |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How to define what to be tracked in PadrePads?\n",
    "First, let's suppose we want to run the following machine learning workflow which is the following simple classification example:\n",
    "```python\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Organize our data\n",
    "label_names = data['target_names']\n",
    "labels = data['target']\n",
    "feature_names = data['feature_names']\n",
    "features = data['data']\n",
    "\n",
    "# Look at our data\n",
    "print(label_names)\n",
    "print('Class label = ', labels[0])\n",
    "print(feature_names)\n",
    "print(features[0])\n",
    "\n",
    "# Split our data\n",
    "train, test, train_labels, test_labels = train_test_split(features,\n",
    "                                                          labels,\n",
    "                                                          test_size=0.33,\n",
    "                                                          random_state=42)\n",
    "\n",
    "# Initialize our classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train our classifier\n",
    "model = gnb.fit(train, train_labels)\n",
    "\n",
    "# Make predictions\n",
    "preds = gnb.predict(test)\n",
    "print(preds)\n",
    "\n",
    "# Evaluate accuracy\n",
    "print(accuracy_score(test_labels, preds))\n",
    "```\n",
    "##### Example\n",
    "Suppose we want to track the data flow of the estimator GaussianNB (inputs and outputs) as well as the parameters of the model and the accuracy metric value.\n",
    "\n",
    "The entry in the mapping file would look like the following:\n",
    "```json\n",
    "{\n",
    "  \"default_hooks\": {\n",
    "    \"modules\": {\n",
    "      \"fns\": {}\n",
    "    },\n",
    "    \"classes\": {\n",
    "      \"fns\": {\n",
    "        \"pypads_init\": [\n",
    "          \"__init__\"\n",
    "        ]\n",
    "      }\n",
    "    },\n",
    "    \"fns\": {}\n",
    "  },\n",
    "  \"algorithms\": [\n",
    "    {\n",
    "      \"name\": \"Gaussian Naive Bayes\",\n",
    "      \"other_names\": [],\n",
    "      \"implementation\": {\n",
    "        \"sklearn\": \"sklearn.naive_bayes.GaussianNB\"\n",
    "      },\n",
    "      \"hooks\": {\n",
    "        \"pypads_fit\": [\n",
    "          \"fit\",\n",
    "          \"fit_predict\",\n",
    "          \"fit_transform\"\n",
    "        ],\n",
    "        \"pypads_predict\": [\n",
    "          \"fit_predict\",\n",
    "          \"predict\"\n",
    "        ],\n",
    "        \"pypads_transform\": [\n",
    "          \"fit_transform\",\n",
    "          \"transform\"\n",
    "        ]\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"sklearn classification metrics\",\n",
    "      \"other_names\": [],\n",
    "      \"implementation\": {\n",
    "        \"sklearn\": \"sklearn.metrics.classification\"\n",
    "      },\n",
    "      \"hooks\": {\n",
    "        \"pypads_metric\": [\n",
    "          \"accuracy_score\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"author\": \"DEMO\",\n",
    "    \"library\": \"sklearn\",\n",
    "    \"library_version\": \"0.19.1\",\n",
    "    \"mapping_version\": \"0.1\"\n",
    "  }\n",
    "}\n",
    "```\n",
    "##### Note: Defining a hook can be done with 3 different way (\"always\", a regex expression for the function name, package name hook)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple method to see logged data\n",
    "import http.server\n",
    "import socketserver\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def setup_server(path,PORT=8000):\n",
    "    web_dir = path\n",
    "    os.chdir(web_dir)\n",
    "\n",
    "    Handler = http.server.SimpleHTTPRequestHandler\n",
    "    httpd = socketserver.TCPServer((\"\", PORT), Handler)\n",
    "    return httpd\n",
    "\n",
    "def archive(output_filename,dir_name):\n",
    "    return shutil.make_archive(output_filename, 'zip', dir_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the PadrePads instance \"tracker\"\n",
    "Adding the mapping file we defined above as a resource to PadrePads can either be done by copying it under pypads/bindings/resources/mapping/ after cloning the source code **OR** by creating an instance of MappingFile class out of the json object and passing it into PadrePads initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehdi/anaconda3/envs/padre37/lib/python3.7/site-packages/networkx/classes/reportviews.py:95: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, Set, Iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:49:01.758 | INFO     | pypads.autolog.mappings:load_mapping:198 - Added mapping file with name: keras_2_3_1.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:49:01.758 | INFO     | pypads.autolog.mappings:load_mapping:198 - Added mapping file with name: keras_2_3_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:49:01.760 | INFO     | pypads.autolog.mappings:load_mapping:198 - Added mapping file with name: sklearn_0_19_1.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:49:01.760 | INFO     | pypads.autolog.mappings:load_mapping:198 - Added mapping file with name: sklearn_0_19_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:49:01.768 | INFO     | pypads.autolog.mappings:load_mapping:198 - Added mapping file with name: keras_2_3_1.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:49:01.768 | INFO     | pypads.autolog.mappings:load_mapping:198 - Added mapping file with name: keras_2_3_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:49:01.769 | INFO     | pypads.autolog.mappings:load_mapping:198 - Added mapping file with name: sklearn_0_19_1.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:49:01.769 | INFO     | pypads.autolog.mappings:load_mapping:198 - Added mapping file with name: sklearn_0_19_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:49:01.771 | INFO     | pypads.autolog.mappings:load_mapping:198 - Added mapping file with name: torch_1_4_0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:49:01.771 | INFO     | pypads.autolog.mappings:load_mapping:198 - Added mapping file with name: torch_1_4_0.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:49:01.842 | INFO     | pypads.functions.pre_run.pre_run:_call:52 - Tracking execution to run with id 15db4229b3d4449ba87afd27cd95fc70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:49:01.842 | INFO     | pypads.functions.pre_run.pre_run:_call:52 - Tracking execution to run with id 15db4229b3d4449ba87afd27cd95fc70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:49:02.115 | WARNING  | pypads.functions.util:check_index:82 - There are uncommitted changes in your git!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:49:02.115 | WARNING  | pypads.functions.util:check_index:82 - There are uncommitted changes in your git!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:49:02.144 | WARNING  | pypads.functions.util:check_index:126 - Checking the index of your repository failed due to Cmd('git') failed due to: exit code(1)\n",
      "  cmdline: git stash push --include-untracked\n",
      "  stderr: 'usage: git stash list [<options>]\n",
      "   or: git stash show [<stash>]\n",
      "   or: git stash drop [-q|--quiet] [<stash>]\n",
      "   or: git stash ( pop | apply ) [--index] [-q|--quiet] [<stash>]\n",
      "   or: git stash branch <branchname> [<stash>]\n",
      "   or: git stash [save [--patch] [-k|--[no-]keep-index] [-q|--quiet]\n",
      "\t\t       [-u|--include-untracked] [-a|--all] [<message>]]\n",
      "   or: git stash clear'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:49:02.144 | WARNING  | pypads.functions.util:check_index:126 - Checking the index of your repository failed due to Cmd('git') failed due to: exit code(1)\n",
      "  cmdline: git stash push --include-untracked\n",
      "  stderr: 'usage: git stash list [<options>]\n",
      "   or: git stash show [<stash>]\n",
      "   or: git stash drop [-q|--quiet] [<stash>]\n",
      "   or: git stash ( pop | apply ) [--index] [-q|--quiet] [<stash>]\n",
      "   or: git stash branch <branchname> [<stash>]\n",
      "   or: git stash [save [--patch] [-k|--[no-]keep-index] [-q|--quiet]\n",
      "\t\t       [-u|--include-untracked] [-a|--all] [<message>]]\n",
      "   or: git stash clear'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:49:02.753 | INFO     | pypads.functions.pre_run.pre_run:_call:52 - Tracking execution to run with id 83adb22365b04f9685b2b0cb569bc30d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:49:02.753 | INFO     | pypads.functions.pre_run.pre_run:_call:52 - Tracking execution to run with id 83adb22365b04f9685b2b0cb569bc30d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:49:03.019 | WARNING  | pypads.functions.util:check_index:82 - There are uncommitted changes in your git!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:49:03.019 | WARNING  | pypads.functions.util:check_index:82 - There are uncommitted changes in your git!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:49:03.046 | WARNING  | pypads.functions.util:check_index:126 - Checking the index of your repository failed due to Cmd('git') failed due to: exit code(1)\n",
      "  cmdline: git stash push --include-untracked\n",
      "  stderr: 'usage: git stash list [<options>]\n",
      "   or: git stash show [<stash>]\n",
      "   or: git stash drop [-q|--quiet] [<stash>]\n",
      "   or: git stash ( pop | apply ) [--index] [-q|--quiet] [<stash>]\n",
      "   or: git stash branch <branchname> [<stash>]\n",
      "   or: git stash [save [--patch] [-k|--[no-]keep-index] [-q|--quiet]\n",
      "\t\t       [-u|--include-untracked] [-a|--all] [<message>]]\n",
      "   or: git stash clear'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:49:03.046 | WARNING  | pypads.functions.util:check_index:126 - Checking the index of your repository failed due to Cmd('git') failed due to: exit code(1)\n",
      "  cmdline: git stash push --include-untracked\n",
      "  stderr: 'usage: git stash list [<options>]\n",
      "   or: git stash show [<stash>]\n",
      "   or: git stash drop [-q|--quiet] [<stash>]\n",
      "   or: git stash ( pop | apply ) [--index] [-q|--quiet] [<stash>]\n",
      "   or: git stash branch <branchname> [<stash>]\n",
      "   or: git stash [save [--patch] [-k|--[no-]keep-index] [-q|--quiet]\n",
      "\t\t       [-u|--include-untracked] [-a|--all] [<message>]]\n",
      "   or: git stash clear'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['malignant' 'benign']\n",
      "Class label =  0\n",
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n",
      "[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
      " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
      " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      " 4.601e-01 1.189e-01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No split information were found in the cache of the current run, individual decision tracking might be missing Truth values, try to decorate you splitter!\n",
      "WARNING:root:No split information were found in the cache of the current run, individual decision tracking might be missing Truth values, try to decorate you splitter!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 0 0 0 1 1 1 0 1 0 1 0 1 1 1 0 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 0\n",
      " 1 0 1 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0\n",
      " 1 1 1 1 1 1 0 1 1 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 1 0 0 1 0 0 1 1 1 0 1 1 0\n",
      " 1 1 0 0 0 1 1 1 0 0 1 1 0 1 0 0 1 1 0 0 0 1 1 1 0 1 1 0 0 1 0 1 1 0 1 0 0\n",
      " 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 0 1 1 1 1 1 1 0 0\n",
      " 0 1 1]\n",
      "0.9414893617021277\n",
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m<ipython-input-2-cebbf16e456d>\u001b[0m(130)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m    129 \u001b[0;31m\u001b[0;32mimport\u001b[0m \u001b[0mipdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m--> 130 \u001b[0;31m\u001b[0mipdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m    131 \u001b[0;31m\u001b[0mdatasets_folder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> temp_dir.name\n",
      "'/tmp/tmpjonr38ms'\n",
      "ipdb> continue\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehdi/anaconda3/envs/padre37/lib/python3.7/site-packages/networkx/drawing/nx_pylab.py:563: MatplotlibDeprecationWarning: \n",
      "The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead.\n",
      "  if not cb.iterable(width):\n",
      "/home/mehdi/anaconda3/envs/padre37/lib/python3.7/site-packages/networkx/drawing/nx_pylab.py:660: MatplotlibDeprecationWarning: \n",
      "The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead.\n",
      "  if cb.iterable(node_size):  # many node sizes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To get the logged results zipped, download them at http://localhost:8000/logs.zip\n"
     ]
    }
   ],
   "source": [
    "mapping_json = {\n",
    "  \"default_hooks\": {\n",
    "    \"modules\": {\n",
    "      \"fns\": {}\n",
    "    },\n",
    "    \"classes\": {\n",
    "      \"fns\": {\n",
    "        \"pypads_init\": [\n",
    "          \"__init__\"\n",
    "        ]\n",
    "      }\n",
    "    },\n",
    "    \"fns\": {}\n",
    "  },\n",
    "  \"algorithms\": [\n",
    "    {\n",
    "      \"name\": \"Gaussian Naive Bayes\",\n",
    "      \"other_names\": [],\n",
    "      \"implementation\": {\n",
    "        \"sklearn\": \"sklearn.naive_bayes.GaussianNB\"\n",
    "      },\n",
    "      \"hooks\": {\n",
    "        \"pypads_fit\": [\n",
    "          \"fit\",\n",
    "          \"fit_predict\",\n",
    "          \"fit_transform\"\n",
    "        ],\n",
    "        \"pypads_predict\": [\n",
    "          \"fit_predict\",\n",
    "          \"predict\"\n",
    "        ],\n",
    "        \"pypads_transform\": [\n",
    "          \"fit_transform\",\n",
    "          \"transform\"\n",
    "        ]\n",
    "      }\n",
    "    },\n",
    "    {\n",
    "      \"name\": \"sklearn classification metrics\",\n",
    "      \"other_names\": [],\n",
    "      \"implementation\": {\n",
    "        \"sklearn\": \"sklearn.metrics.classification\"\n",
    "      },\n",
    "      \"hooks\": {\n",
    "        \"pypads_metric\": [\n",
    "          \"accuracy_*\"\n",
    "        ]\n",
    "      }\n",
    "    },\n",
    "      {\n",
    "      \"name\": \"sklearn datasets\",\n",
    "      \"other_names\": [],\n",
    "      \"implementation\":{\n",
    "          \"sklearn\": \"sklearn.datasets.base\"\n",
    "      },\n",
    "      \"hooks\": {\n",
    "          \"pypads_dataset\": [\"load_breast_cancer\"]\n",
    "      }  \n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"author\": \"DEMO\",\n",
    "    \"library\": \"sklearn\",\n",
    "    \"library_version\": \"0.19.1\",\n",
    "    \"mapping_version\": \"0.1\"\n",
    "  }\n",
    "}\n",
    "# Temporary directory to store resutls in (Default directory is $HOME/.mlruns/)\n",
    "from tempfile import TemporaryDirectory\n",
    "import threading\n",
    "\n",
    "# MappingFile instance\n",
    "from pypads.autolog.mappings import MappingFile\n",
    "import json\n",
    "mapping_example = MappingFile(\"sklearn_example\", mapping_json)\n",
    "\n",
    "temp_dir = TemporaryDirectory()\n",
    "\n",
    "# Initializing PadrePads\n",
    "from padrepads.base import PyPadrePads\n",
    "tracker = PyPadrePads(uri=temp_dir.name,mapping=mapping_example)\n",
    "\n",
    "###### Script #######\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()\n",
    "\n",
    "# Organize our data\n",
    "label_names = data['target_names']\n",
    "labels = data['target']\n",
    "feature_names = data['feature_names']\n",
    "features = data['data']\n",
    "\n",
    "# Look at our data\n",
    "print(label_names)\n",
    "print('Class label = ', labels[0])\n",
    "print(feature_names)\n",
    "print(features[0])\n",
    "\n",
    "# Split our data\n",
    "train, test, train_labels, test_labels = train_test_split(features,\n",
    "                                                          labels,\n",
    "                                                          test_size=0.33,\n",
    "                                                          random_state=42)\n",
    "\n",
    "# Initialize our classifier\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# Train our classifier\n",
    "model = gnb.fit(train, train_labels)\n",
    "\n",
    "# Make predictions\n",
    "preds = gnb.predict(test)\n",
    "print(preds)\n",
    "\n",
    "# Evaluate accuracy\n",
    "print(accuracy_score(test_labels, preds))\n",
    "\n",
    "# getting uri for the experiment folder and the dataset folder\n",
    "run = tracker.api.active_run()\n",
    "experiment_folder = run.info.experiment_id\n",
    "\n",
    "datasets = tracker.mlf.get_experiment_by_name(\"datasets\")\n",
    "datasets_folder = datasets.experiment_id\n",
    "\n",
    "tracker.api.end_run()\n",
    "###### Script #######\n",
    "\n",
    "###### Logged results (to show the folder structure) #######\n",
    "\n",
    "path = archive(temp_dir.name+'/logs', temp_dir.name)\n",
    "\n",
    "server = setup_server(temp_dir.name)\n",
    "\n",
    "threading.Thread(target=server.serve_forever).start()\n",
    "\n",
    "from IPython.display import IFrame\n",
    "\n",
    "experiment_frame = IFrame(\"http://localhost:8000/\"+experiment_folder,width=800, height=650)\n",
    "\n",
    "dataset_frame = IFrame(\"http://localhost:8000/\"+datasets_folder,width=800, height=650)\n",
    "\n",
    "print('To get the logged results zipped, download them at http://localhost:8000/logs.zip')\n",
    "###### Logged results #######\n",
    "tracker.deactivate_tracking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"650\"\n",
       "            src=\"http://localhost:8000/0\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f4fbee9cb00>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "experiment_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2020 13:49:39] \"GET /0 HTTP/1.1\" 301 -\n",
      "127.0.0.1 - - [26/May/2020 13:49:39] \"GET /0/ HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"650\"\n",
       "            src=\"http://localhost:8000/1\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f4fbee9cc88>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.shutdown()\n",
    "temp_dir.cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "padre37",
   "language": "python",
   "name": "padre37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
