{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PadrePads custom loggers\n",
    "To develop custom loggers, we need to write a class that inherits from the base class LoggingFunction. Then, those custom loggers can be mapped to events of the user choice in the parameter mapping of the PyPads class. \n",
    "\n",
    "\n",
    "```python\n",
    "from pypads.functions.loggers.base_logger import LoggingFunction\n",
    "class CustomLogger(LoggingFunction):\n",
    "    \"\"\"\n",
    "    This class would represents the custom logger.\n",
    "    \"\"\"\n",
    "    def __pre__(self, ctx, *args, _pypads_env, _args, _kwargs, **kwargs):\n",
    "        # The custom code you want to execute before calling the tracked function.\n",
    "        # ctx: can be either the class of the tracked function, the module, or None.\n",
    "        # _args, _kwarg\n",
    "        \n",
    "    def __post__(self, ctx, *args, _pypads_env, _pypads_pre_return, _pypads_result, _args, _kwargs, **kwargs):\n",
    "        # The custom code to be executed after the call of the tracked function where \"_pypads_pre_return\"\n",
    "        # and \"_pypads_result\" are the return value of self.__pre__ and the tracked function respectively\"\n",
    "        \n",
    "```\n",
    "\n",
    "##### Example\n",
    "\n",
    "Let's say we want to log the accuracy score from the previous example but we want to log other metrics that we can compute using the Truth and Predicted values along with it. This should be done in the __post__ method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypads.functions.loggers.base_logger import LoggingFunction\n",
    "import mlflow\n",
    "from mlflow.utils.autologging_utils import try_mlflow_log\n",
    "from pypads import logger\n",
    "\n",
    "class custom_metric(LoggingFunction):\n",
    "    def __post__(self, ctx, *args, _pypads_env, _pypads_pre_return, _pypads_result, _args, _kwargs, **kwargs):\n",
    "        accuracy_score = _pypads_result\n",
    "        # Logging the accuracy score as an mlflow metric.\n",
    "        if isinstance(accuracy_score, float):\n",
    "            filename = _pypads_env.call.call_id.context.container.__name__ + \".\" + _pypads_env.call.call_id.wrappee.__name__ + \".txt\"\n",
    "            try_mlflow_log(mlflow.log_metric, filename, accuracy_score, step=_pypads_env.call.call_id.call_number)\n",
    "        else:\n",
    "            logger.warning(\"Mlflow metrics have to be doubles. Could log the return value of type '\" + \n",
    "                           str( type(accuracy_score)) + \"' of '\" + _pypads_env.call.call_id.context.container.__name__ + \n",
    "                           \".\" + _pypads_env.call.call_id.wrappee.__name__ + \"' as artifact instead.\")\n",
    "            \n",
    "        # Let's say we want to log f1_score whenver someone computes the accuracy score just to compare \n",
    "        # since accuracy alone can be misleading in some use cases.\n",
    "        \n",
    "        from sklearn.metrics import f1_score\n",
    "        f1 = f1_score(*_args,**_kwargs)\n",
    "        print(\"Computing f1_score\")\n",
    "        if isinstance(f1, float):\n",
    "            filename = _pypads_env.call.call_id.context.container.__name__ + \".\" + f1_score.__qualname__ + \".CUSTOM_LOGGER.txt\"\n",
    "            try_mlflow_log(mlflow.log_metric, filename, f1, step=_pypads_env.call.call_id.call_number)\n",
    "        else:\n",
    "            logger.warning(\"Mlflow metrics have to be doubles.\")\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Custom mapping file to define the hook for our custom logger\n",
    "* Event : \"pypads_metrics\"\n",
    "* Hook : \"accuracy_score\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom mapping file \n",
    "mapping_json = {\n",
    "  \"default_hooks\": {\n",
    "    \"modules\": {\n",
    "      \"fns\": {}\n",
    "    },\n",
    "    \"classes\": {\n",
    "      \"fns\": {\n",
    "        \"pypads_init\": [\n",
    "          \"__init__\"\n",
    "        ]\n",
    "      }\n",
    "    },\n",
    "    \"fns\": {}\n",
    "  },\n",
    "  \"algorithms\": [\n",
    "    {\n",
    "      \"name\": \"sklearn classification metrics\",\n",
    "      \"other_names\": [],\n",
    "      \"implementation\": {\n",
    "        \"sklearn\": \"sklearn.metrics.classification\"\n",
    "      },\n",
    "      \"hooks\": {\n",
    "        \"pypads_metric\": [\n",
    "          \"accuracy_score\"\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ],\n",
    "  \"metadata\": {\n",
    "    \"author\": \"DEMO\",\n",
    "    \"library\": \"sklearn\",\n",
    "    \"library_version\": \"0.19.1\",\n",
    "    \"mapping_version\": \"0.1\"\n",
    "  }\n",
    "}\n",
    "\n",
    "# MappingFile instance\n",
    "from pypads.autolog.mappings import MappingFile\n",
    "import json\n",
    "mapping_example = MappingFile(\"sklearn_example1\", mapping_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should then link the event \"pypads_metric\" to our new custom logger function by overwriting the currently mapped logging function **Metric** in DEFAULT_LOGGING_FNS. This could be done by passing the following dictionary,\n",
    "\n",
    "```python\n",
    "from pypads.base import DEFAULT_LOGGING_FNS\n",
    "DEFAULT_LOGGING_FNS[\"metric\"] = custom_metric()\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'parameters': <pypads.functions.analysis.validation.parameters.Parameters at 0x7f573b122550>,\n",
       " 'output': <pypads.functions.loggers.data_flow.Output at 0x7f573b1225f8>,\n",
       " 'input': <pypads.functions.loggers.data_flow.Input at 0x7f573b1226a0>,\n",
       " 'hardware': {<pypads.functions.loggers.hardware.Cpu at 0x7f573b122748>,\n",
       "  <pypads.functions.loggers.hardware.Disk at 0x7f573b122898>,\n",
       "  <pypads.functions.loggers.hardware.Ram at 0x7f573b1227f0>},\n",
       " 'metric': <__main__.custom_metric at 0x7f5774622f98>,\n",
       " 'autolog': <pypads.functions.loggers.mlflow.mlflow_autolog.MlflowAutologger at 0x7f573b1229e8>,\n",
       " 'pipeline': <pypads.functions.loggers.pipeline_detection.PipelineTracker at 0x7f573b122a90>,\n",
       " 'log': <pypads.functions.loggers.debug.Log at 0x7f573b122b38>,\n",
       " 'init': <pypads.functions.loggers.debug.LogInit at 0x7f573b122be0>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pypads.base import DEFAULT_LOGGING_FNS\n",
    "DEFAULT_LOGGING_FNS[\"metric\"] = custom_metric()\n",
    "DEFAULT_LOGGING_FNS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Utilities "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple method to see logged data\n",
    "import http.server\n",
    "import socketserver\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "def setup_server(path,PORT=8000):\n",
    "    web_dir = path\n",
    "    os.chdir(web_dir)\n",
    "\n",
    "    Handler = http.server.SimpleHTTPRequestHandler\n",
    "    httpd = socketserver.TCPServer((\"\", PORT), Handler)\n",
    "    return httpd\n",
    "\n",
    "def archive(output_filename,dir_name):\n",
    "    return shutil.make_archive(output_filename, 'zip', dir_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Script to test our custom logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mehdi/anaconda3/envs/padre37/lib/python3.7/site-packages/networkx/classes/reportviews.py:95: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, Set, Iterable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:57:29.850 | INFO     | pypads.autolog.mappings:load_mapping:198 - Added mapping file with name: keras_2_3_1.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:57:29.850 | INFO     | pypads.autolog.mappings:load_mapping:198 - Added mapping file with name: keras_2_3_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:57:29.852 | INFO     | pypads.autolog.mappings:load_mapping:198 - Added mapping file with name: sklearn_0_19_1.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:57:29.852 | INFO     | pypads.autolog.mappings:load_mapping:198 - Added mapping file with name: sklearn_0_19_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:57:29.857 | INFO     | pypads.autolog.mappings:load_mapping:198 - Added mapping file with name: keras_2_3_1.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:57:29.857 | INFO     | pypads.autolog.mappings:load_mapping:198 - Added mapping file with name: keras_2_3_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:57:29.859 | INFO     | pypads.autolog.mappings:load_mapping:198 - Added mapping file with name: sklearn_0_19_1.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:57:29.859 | INFO     | pypads.autolog.mappings:load_mapping:198 - Added mapping file with name: sklearn_0_19_1.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:57:29.861 | INFO     | pypads.autolog.mappings:load_mapping:198 - Added mapping file with name: torch_1_4_0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:57:29.861 | INFO     | pypads.autolog.mappings:load_mapping:198 - Added mapping file with name: torch_1_4_0.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:57:29.928 | INFO     | pypads.functions.pre_run.pre_run:_call:52 - Tracking execution to run with id ee0c316620ca4f46a3c6640b1b7aae32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:57:29.928 | INFO     | pypads.functions.pre_run.pre_run:_call:52 - Tracking execution to run with id ee0c316620ca4f46a3c6640b1b7aae32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:57:30.211 | WARNING  | pypads.functions.util:check_index:82 - There are uncommitted changes in your git!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:57:30.211 | WARNING  | pypads.functions.util:check_index:82 - There are uncommitted changes in your git!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:57:30.236 | WARNING  | pypads.functions.util:check_index:126 - Checking the index of your repository failed due to Cmd('git') failed due to: exit code(1)\n",
      "  cmdline: git stash push --include-untracked\n",
      "  stderr: 'usage: git stash list [<options>]\n",
      "   or: git stash show [<stash>]\n",
      "   or: git stash drop [-q|--quiet] [<stash>]\n",
      "   or: git stash ( pop | apply ) [--index] [-q|--quiet] [<stash>]\n",
      "   or: git stash branch <branchname> [<stash>]\n",
      "   or: git stash [save [--patch] [-k|--[no-]keep-index] [-q|--quiet]\n",
      "\t\t       [-u|--include-untracked] [-a|--all] [<message>]]\n",
      "   or: git stash clear'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-05-26 13:57:30.236 | WARNING  | pypads.functions.util:check_index:126 - Checking the index of your repository failed due to Cmd('git') failed due to: exit code(1)\n",
      "  cmdline: git stash push --include-untracked\n",
      "  stderr: 'usage: git stash list [<options>]\n",
      "   or: git stash show [<stash>]\n",
      "   or: git stash drop [-q|--quiet] [<stash>]\n",
      "   or: git stash ( pop | apply ) [--index] [-q|--quiet] [<stash>]\n",
      "   or: git stash branch <branchname> [<stash>]\n",
      "   or: git stash [save [--patch] [-k|--[no-]keep-index] [-q|--quiet]\n",
      "\t\t       [-u|--include-untracked] [-a|--all] [<message>]]\n",
      "   or: git stash clear'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing f1_score\n",
      "To get the logged results zipped, download them at http://localhost:8001/logs.zip\n"
     ]
    }
   ],
   "source": [
    "# Temporary directory to store resutls in (Default directory is $HOME/.mlruns/)\n",
    "from tempfile import TemporaryDirectory\n",
    "import threading\n",
    "temp_dir = TemporaryDirectory()\n",
    "\n",
    "# Initializing PyPads\n",
    "from padrepads.base import PyPadrePads\n",
    "custom_logging = {\"metric\": custom_metric()}\n",
    "tracker = PyPadrePads(uri=temp_dir.name,mapping=mapping_example, logging_fns=custom_logging)\n",
    "\n",
    "###### Script #######\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# From the previous experiment\n",
    "test_labels = np.asarray([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
    "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
    "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
    "       0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
    "       1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
    "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
    "       0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1])\n",
    "\n",
    "preds = np.asarray([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
    "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
    "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
    "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0,\n",
    "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
    "       0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
    "       1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
    "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
    "       0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1])\n",
    "\n",
    "# Computing the accuracy_score tracked by our custom logger\n",
    "accuracy = accuracy_score(test_labels, preds)\n",
    "\n",
    "###### getting uri for metrics folder\n",
    "\n",
    "run = tracker.api.active_run()\n",
    "metrics = run.info.run_id+'/'+'metrics'\n",
    "\n",
    "tracker.api.end_run()\n",
    "\n",
    "##### Logged results (to show the folder structure) #######\n",
    "\n",
    "path = archive(temp_dir.name+'/logs', temp_dir.name)\n",
    "\n",
    "\n",
    "\n",
    "server = setup_server(temp_dir.name+'/'+run.info.experiment_id,PORT=8001)\n",
    "\n",
    "threading.Thread(target=server.serve_forever).start()\n",
    "\n",
    "from IPython.display import IFrame\n",
    "\n",
    "frame = IFrame(\"http://localhost:8001/\"+metrics,width=800, height=650)\n",
    "\n",
    "print('To get the logged results zipped, download them at http://localhost:8001/logs.zip')\n",
    "###### Logged results #######\n",
    "tracker.deactivate_tracking()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800\"\n",
       "            height=\"650\"\n",
       "            src=\"http://localhost:8001/ee0c316620ca4f46a3c6640b1b7aae32/metrics\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f574e9af860>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [26/May/2020 13:57:30] \"GET /ee0c316620ca4f46a3c6640b1b7aae32/metrics HTTP/1.1\" 301 -\n",
      "127.0.0.1 - - [26/May/2020 13:57:30] \"GET /ee0c316620ca4f46a3c6640b1b7aae32/metrics/ HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see there is a logged f1_score that was computed inside our custom logger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "server.shutdown()\n",
    "temp_dir.cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "padre37",
   "language": "python",
   "name": "padre37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
